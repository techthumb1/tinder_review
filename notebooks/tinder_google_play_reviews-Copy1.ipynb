{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tinder Google Play Reviews\n",
    "\n",
    "Custom Dataset Provided By: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Domain Knowledge\n",
    "\n",
    "Since from a personal standpoint, no domain knowledge is present for any background information, we will leave the model up for interpretation for a quick analysis. \n",
    "\n",
    "How can we gather a story from the dataset?\n",
    "What can we determine?\n",
    "\n",
    "The data is primarily string data with two integer types, there are several directions we could take with this dataset:\n",
    "- Predict thumbsUpCount\n",
    "- Is there a relationship between username and content\n",
    "- Relationship between content and at\n",
    "- Can we classify reviews into topics\n",
    "- What is the most common level of sentiment from reviews\n",
    "\n",
    "In addition, the techniques that we could use:\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "- Dimensionality Reduction\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- Latent Dirichlet Allocation\n",
    "\n",
    "and so forth. I think for this project we can answer three of these questions by the end of our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530253, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gp:AOqpTOH2EGdi4f1cyGMD3yuybAw8AAEz61LalnOoPtr...</td>\n",
       "      <td>Christina B.</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/AOh14...</td>\n",
       "      <td>Won't let me link my spotify</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3.0</td>\n",
       "      <td>2022-03-18 22:00:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gp:AOqpTOEAwIce8kQ2UdDFb0_RzaZGhjwyHTIk3mI1IaZ...</td>\n",
       "      <td>Franscois Matthee</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/AATXAJ...</td>\n",
       "      <td>This is not a dating app its a shity version o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-18 21:57:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewId           userName  \\\n",
       "0  gp:AOqpTOH2EGdi4f1cyGMD3yuybAw8AAEz61LalnOoPtr...       Christina B.   \n",
       "1  gp:AOqpTOEAwIce8kQ2UdDFb0_RzaZGhjwyHTIk3mI1IaZ...  Franscois Matthee   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/a-/AOh14...   \n",
       "1  https://play-lh.googleusercontent.com/a/AATXAJ...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0                       Won't let me link my spotify      1              0   \n",
       "1  This is not a dating app its a shity version o...      1              0   \n",
       "\n",
       "  reviewCreatedVersion                   at replyContent repliedAt  \n",
       "0               13.3.0  2022-03-18 22:00:58          NaN       NaN  \n",
       "1                  NaN  2022-03-18 21:57:41          NaN       NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and inspect our dataset\n",
    "tinder = pd.read_csv('/Users/jasonrobinson/Documents/Projects/tinder_google_play_reviews.csv')\n",
    "\n",
    "print(tinder.shape)\n",
    "tinder.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy.cli\n",
    "#spacy.cli.download(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530253,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 530253 entries, 0 to 530252\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   reviewId              530253 non-null  object\n",
      " 1   userName              530248 non-null  object\n",
      " 2   userImage             530253 non-null  object\n",
      " 3   content               528908 non-null  object\n",
      " 4   score                 530253 non-null  int64 \n",
      " 5   thumbsUpCount         530253 non-null  int64 \n",
      " 6   reviewCreatedVersion  423368 non-null  object\n",
      " 7   at                    530253 non-null  object\n",
      " 8   replyContent          47714 non-null   object\n",
      " 9   repliedAt             47714 non-null   object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 40.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# See non-nulls and data types\n",
    "print(tinder['content'].shape)\n",
    "tinder.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1345"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have some missing values, take a closer look at content\n",
    "tinder['content'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can just drop the 1345 rows since the dataset is so large\n",
    "tinder = tinder.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613                                               Facebook?\n",
       "650       Took away the daily free super like and now yo...\n",
       "830       Only works like 30% of time. I almost always g...\n",
       "959       app is broken. never found a single match insp...\n",
       "2104      I've been using Tinder since 2019. I've met a ...\n",
       "                                ...                        \n",
       "530245                            Y Facebook sign up only ?\n",
       "530247    Buggy, after login the hour glass just keep sp...\n",
       "530249    Tinder is extremely buggy on the galaxy S4 act...\n",
       "530250                                      Keeps crashing.\n",
       "530251    Crashes. Doesn't load. Total failure. Take it ...\n",
       "Name: content, Length: 41091, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trimmed our datset down to 41000\n",
    "tinder['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get our summary statistics\n",
    "#tinder.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In answering the status of a relationship between **content** and **at** we will filter to just those two columns. Let's see if there is a correlation between date/time and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335682</th>\n",
       "      <td>None</td>\n",
       "      <td>2017-06-29 08:42:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289654</th>\n",
       "      <td>None</td>\n",
       "      <td>2018-03-11 22:03:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116987</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-05-21 06:27:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>None</td>\n",
       "      <td>2022-03-07 03:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297777</th>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-18 22:59:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252529</th>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-06 03:25:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140325</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-01-21 14:13:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138553</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-01-30 07:47:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87865</th>\n",
       "      <td>None</td>\n",
       "      <td>2020-10-19 12:06:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484063</th>\n",
       "      <td>None</td>\n",
       "      <td>2015-01-08 01:31:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       content                   at\n",
       "335682    None  2017-06-29 08:42:33\n",
       "289654    None  2018-03-11 22:03:28\n",
       "116987    None  2020-05-21 06:27:31\n",
       "2036      None  2022-03-07 03:51:00\n",
       "297777    None  2018-01-18 22:59:11\n",
       "252529    None  2018-10-06 03:25:30\n",
       "140325    None  2020-01-21 14:13:14\n",
       "138553    None  2020-01-30 07:47:12\n",
       "87865     None  2020-10-19 12:06:19\n",
       "484063    None  2015-01-08 01:31:32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at 10 random rows\n",
    "tinder[['content', 'at']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm that our dates are really objects(strings), \n",
    "# which is what we need to preprocess our text\n",
    "tinder['content'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to datetime\n",
    "tinder['at'] = pd.to_datetime(tinder['at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613      2022-03-15 10:13:13\n",
       "650      2022-03-15 03:53:09\n",
       "830      2022-03-14 05:19:01\n",
       "959      2022-03-13 12:15:34\n",
       "2104     2022-03-06 16:56:47\n",
       "                 ...        \n",
       "530245   2013-07-15 23:44:37\n",
       "530247   2013-07-15 23:29:17\n",
       "530249   2013-07-15 22:43:41\n",
       "530250   2013-07-15 22:27:15\n",
       "530251   2013-07-15 22:20:31\n",
       "Name: at, Length: 41091, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure change (8.8-years of data)\n",
    "tinder['at'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Tokenization with Spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the option of using spacy but for demonstration purposes\n",
    "# it is also good to know how to create your own functions\n",
    "\n",
    "tinder['content'] = tinder['content'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "\n",
    "# Remove Emails\n",
    "tinder['content'] = tinder['content'].apply(lambda x: re.sub('From: \\S+@\\S+', '', x))\n",
    "\n",
    "# Remove non-alphanumeric characters\n",
    "tinder['content'] = tinder['content'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
    "\n",
    "# Remove extra whitespace and lowercase text\n",
    "tinder['content'] = tinder['content'].apply(lambda x: ' '.join(x.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_lemmas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q3/0g1f31211lbgj741dfjd4r5c0000gn/T/ipykernel_11198/3171249559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpandarallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtinder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemmas'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtinder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_lemmas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_lemmas' is not defined"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "tinder['lemmas'] = tinder['content'].parallel_apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinder['content'] = tinder['clean_text'].progress_apply(lambda x: [token.lemma_ for token in nlp(x) if (token.is_stop != True) and (token.is_punct != True) and (len(token) > 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will work with spacy and gensim just for demonstration purposes\n",
    "nlp.Defaults.stop_words\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(str(tinder['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = []\n",
    "#\n",
    "#\"\"\" Update those tokens w/o stopwords\"\"\"\n",
    "#for doc in tokenizer.pipe(tinder['content'], batch_size=500):\n",
    "#    \n",
    "#    doc_tokens = []\n",
    "#    \n",
    "#    for token in doc:\n",
    "#        if (token.is_stop == False) & (token.is_punct == False):\n",
    "#            doc_tokens.append(token.text.lower())\n",
    "#\n",
    "#    tokens.append(doc_tokens)\n",
    "#\n",
    "#tinder['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = count(df['tokens'])\n",
    "\n",
    "wc_top20 = wc[wc['rank'] <= 20]\n",
    "\n",
    "squarify.plot(sizes=wc_top20['pct_total'], label=wc_top20['word'], alpha=.8 )\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Tokenization with Gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could also decide to use a custom function of our own\n",
    "\n",
    "#def tokenize(str):\n",
    "#    idx = [x for x, v in enumerate(str) if v == '\\\"']\n",
    "#    if len(idx) % 2 != 0:\n",
    "#        idx = idx[:-1]\n",
    "#    memory = {}\n",
    "#    for i in range(0, len(idx), 2):\n",
    "#        val = str[idx[i]:idx[i+1]+1]\n",
    "#        key = \"_\"*(len(val)-1)+\"{0}\".format(i)\n",
    "#        memory[key] = val\n",
    "#        str = str.replace(memory[key], key, 1)        \n",
    "#    return [memory.get(token, token) for token in str.split(\",\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create a fuction which takes a corpus of document and \n",
    "# returns and dataframe of word counts for us to analyze.\n",
    "def count(docs):\n",
    "\n",
    "        word_counts = Counter()\n",
    "        appears_in = Counter()\n",
    "        \n",
    "        total_docs = len(docs)\n",
    "\n",
    "        for doc in docs:\n",
    "            word_counts.update(doc)\n",
    "            appears_in.update(set(doc))\n",
    "\n",
    "        temp = zip(word_counts.keys(), word_counts.values())\n",
    "        \n",
    "        wc = pd.DataFrame(temp, columns = ['word', 'count'])\n",
    "\n",
    "        wc['rank'] = wc['count'].rank(method='first', ascending=False)\n",
    "        total = wc['count'].sum()\n",
    "\n",
    "        wc['pct_total'] = wc['count'].apply(lambda x: x / total)\n",
    "        \n",
    "        wc = wc.sort_values(by='rank')\n",
    "        wc['cul_pct_total'] = wc['pct_total'].cumsum()\n",
    "\n",
    "        t2 = zip(appears_in.keys(), appears_in.values())\n",
    "        ac = pd.DataFrame(t2, columns=['word', 'appears_in'])\n",
    "        wc = ac.merge(wc, on='word')\n",
    "\n",
    "        wc['appears_in_pct'] = wc['appears_in'].apply(lambda x: x / total_docs)\n",
    "        \n",
    "        return wc.sort_values(by='rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "wc = count(df['tokens'])\n",
    "print(wc.shape)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Distribution Plot\n",
    "sns.lineplot(x='rank', y='cul_pct_total', data=wc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc[wc['rank'] <= 100]['cul_pct_total'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NNse",
   "language": "python",
   "name": "u4-s1-nns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
